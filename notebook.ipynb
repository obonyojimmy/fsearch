{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'fsearch-3.9 (Python 3.9.19)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n fsearch-3.9 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "## install fsearch package \n",
    "!python -m pip install -q -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fsearch.config import Config\n",
    "\n",
    "config = Config(**{'Server': 'abc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fsearch.utils import read_file\n",
    "\n",
    "filepath = \"samples/200k.txt\"\n",
    "file_contents = read_file(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "native_search: False\n",
      "regex_search: False\n",
      "rabin_karp: False\n",
      "kmp_search: False\n",
      "aho_corasick: False\n"
     ]
    }
   ],
   "source": [
    "from fsearch.algorithms import native_search, regex_search, rabin_karp_search, kmp_search, aho_corasick_search\n",
    "\n",
    "query = \"13;0;1;26;0;9;4;0;\"\n",
    "query = \"13;0;1;\"\n",
    "## native_search\n",
    "found = native_search(file_contents, query)\n",
    "print('native_search:', found)\n",
    "## regex_search\n",
    "found = regex_search(file_contents, query)\n",
    "print('regex_search:', found)\n",
    "found = rabin_karp_search(file_contents, query)\n",
    "print('rabin_karp:', found)\n",
    "found = kmp_search(file_contents, query)\n",
    "print('kmp_search:', found)\n",
    "found = aho_corasick_search(file_contents, query)\n",
    "print('aho_corasick:', found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "contents = \"\"\"13;0;1;26;0;9;4;0;\n",
    "11;0;23;16;0;19;5;0;\n",
    "9;0;1;6;0;10;5;0;\n",
    "11;0;23;11;0;19;5;0;\n",
    "17;0;1;26;0;7;3;0;\n",
    "3;0;1;28;0;7;3;0;\n",
    "4;0;1;28;0;8;3;0;\n",
    "5;0;1;26;0;8;3;0; \n",
    "\"\"\"\n",
    "\n",
    "query_1 = \"11;0;23;11;0;19;5;0;\"\n",
    "query_2 = \"11;0;23;11;0;19;5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rabin_karp (q1): True\n",
      "rabin_karp (q2): False\n"
     ]
    }
   ],
   "source": [
    "def rabin_karp_search(pattern, text):\n",
    "    \"\"\"\n",
    "    Rabin-Karp algorithm to find a full line match of a pattern in the text.\n",
    "    \n",
    "    :param pattern: The pattern string to search for.\n",
    "    :param text: The text in which to search for the pattern.\n",
    "    :return: True if the pattern matches any full line in the text, otherwise False.\n",
    "    \"\"\"\n",
    "    if not pattern or not text:\n",
    "        return False\n",
    "\n",
    "    # Define a prime number for the hash function\n",
    "    prime = 101\n",
    "\n",
    "    # Calculate the length of the pattern\n",
    "    m = len(pattern)\n",
    "\n",
    "    # Initialize hash values for pattern\n",
    "    pattern_hash = 0\n",
    "\n",
    "    # Calculate the hash value of the pattern\n",
    "    for i in range(m):\n",
    "        pattern_hash = (prime * pattern_hash + ord(pattern[i]))\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        n = len(line)\n",
    "        if n != m:\n",
    "            continue\n",
    "        \n",
    "        # Initialize hash value for current line\n",
    "        current_hash = 0\n",
    "        for i in range(m):\n",
    "            current_hash = (prime * current_hash + ord(line[i]))\n",
    "\n",
    "        # Compare the hash values\n",
    "        if pattern_hash == current_hash:\n",
    "            # Check for exact match to avoid hash collision\n",
    "            if line == pattern:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "print('rabin_karp (q1):', rabin_karp_search(query_1, contents))  # Output: True\n",
    "print('rabin_karp (q2):', rabin_karp_search(query_2, contents))  # Output: False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmp_search (q1): True\n",
      "kmp_search (q2): False\n"
     ]
    }
   ],
   "source": [
    "def kmp_search(pattern, text):\n",
    "    \"\"\"\n",
    "    KMP algorithm to find a full line match of a pattern in the text.\n",
    "\n",
    "    :param pattern: The pattern string to search for.\n",
    "    :param text: The text in which to search for the pattern.\n",
    "    :return: True if the pattern matches any full line in the text, otherwise False.\n",
    "    \"\"\"\n",
    "    def compute_lps(pattern):\n",
    "        \"\"\"\n",
    "        Compute the longest prefix which is also suffix array (lps) for the pattern.\n",
    "\n",
    "        :param pattern: The pattern string.\n",
    "        :return: The lps array.\n",
    "        \"\"\"\n",
    "        m = len(pattern)\n",
    "        lps = [0] * m\n",
    "        length = 0\n",
    "        i = 1\n",
    "\n",
    "        while i < m:\n",
    "            if pattern[i] == pattern[length]:\n",
    "                length += 1\n",
    "                lps[i] = length\n",
    "                i += 1\n",
    "            else:\n",
    "                if length != 0:\n",
    "                    length = lps[length - 1]\n",
    "                else:\n",
    "                    lps[i] = 0\n",
    "                    i += 1\n",
    "\n",
    "        return lps\n",
    "\n",
    "    def kmp_search_line(pattern, line):\n",
    "        \"\"\"\n",
    "        KMP search for a pattern in a single line.\n",
    "\n",
    "        :param pattern: The pattern string.\n",
    "        :param line: The line of text.\n",
    "        :return: True if the pattern matches the full line, otherwise False.\n",
    "        \"\"\"\n",
    "        m = len(pattern)\n",
    "        n = len(line)\n",
    "        \n",
    "        if m != n:\n",
    "            return False\n",
    "        \n",
    "        lps = compute_lps(pattern)\n",
    "        i = 0  # index for line\n",
    "        j = 0  # index for pattern\n",
    "\n",
    "        while i < n:\n",
    "            if pattern[j] == line[i]:\n",
    "                i += 1\n",
    "                j += 1\n",
    "\n",
    "            if j == m:\n",
    "                return True\n",
    "            elif i < n and pattern[j] != line[i]:\n",
    "                if j != 0:\n",
    "                    j = lps[j - 1]\n",
    "                else:\n",
    "                    i += 1\n",
    "\n",
    "        return False\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        if kmp_search_line(pattern, line):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Example usage\n",
    "print('kmp_search (q1):', kmp_search(query_1, contents))  # Output: True\n",
    "print('kmp_search (q2):', kmp_search(query_2, contents))  # Output: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aho_corasick_search (q1): True\n",
      "aho_corasick_search (q2): False\n"
     ]
    }
   ],
   "source": [
    "class AhoCorasick:\n",
    "    def __init__(self):\n",
    "        self.goto = {}\n",
    "        self.output = {}\n",
    "        self.fail = {}\n",
    "        self.new_state = 0\n",
    "\n",
    "    def add_pattern(self, pattern):\n",
    "        state = 0\n",
    "        for char in pattern:\n",
    "            if (state, char) not in self.goto:\n",
    "                self.new_state += 1\n",
    "                self.goto[(state, char)] = self.new_state\n",
    "            state = self.goto[(state, char)]\n",
    "        self.output[state] = pattern\n",
    "\n",
    "    def build_automaton(self):\n",
    "        from collections import deque\n",
    "        queue = deque()\n",
    "\n",
    "        for char in {key[1] for key in self.goto if key[0] == 0}:\n",
    "            state = self.goto[(0, char)]\n",
    "            self.fail[state] = 0\n",
    "            queue.append(state)\n",
    "\n",
    "        while queue:\n",
    "            r = queue.popleft()\n",
    "            for key in {key[1] for key in self.goto if key[0] == r}:\n",
    "                s = self.goto[(r, key)]\n",
    "                queue.append(s)\n",
    "                state = self.fail[r]\n",
    "                while (state, key) not in self.goto and state != 0:\n",
    "                    state = self.fail[state]\n",
    "                if (state, key) in self.goto:\n",
    "                    self.fail[s] = self.goto[(state, key)]\n",
    "                else:\n",
    "                    self.fail[s] = 0\n",
    "                if self.fail[s] in self.output:\n",
    "                    self.output[s] = self.output[self.fail[s]]\n",
    "\n",
    "    def search(self, text):\n",
    "        state = 0\n",
    "        results = []\n",
    "        for index, char in enumerate(text):\n",
    "            while (state, char) not in self.goto and state != 0:\n",
    "                state = self.fail[state]\n",
    "            if (state, char) in self.goto:\n",
    "                state = self.goto[(state, char)]\n",
    "                if state in self.output:\n",
    "                    results.append((index - len(self.output[state]) + 1, self.output[state]))\n",
    "            else:\n",
    "                state = 0\n",
    "        return results\n",
    "\n",
    "def aho_corasick_search(pattern, text):\n",
    "    \"\"\"\n",
    "    Aho-Corasick algorithm to find a full line match of a pattern in the text.\n",
    "\n",
    "    :param pattern: The pattern string to search for.\n",
    "    :param text: The text in which to search for the pattern.\n",
    "    :return: True if the pattern matches any full line in the text, otherwise False.\n",
    "    \"\"\"\n",
    "    aho = AhoCorasick()\n",
    "    aho.add_pattern(pattern)\n",
    "    aho.build_automaton()\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        if len(line) == len(pattern):\n",
    "            matches = aho.search(line)\n",
    "            for _, match in matches:\n",
    "                if match == pattern:\n",
    "                    return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Example usage\n",
    "print('aho_corasick_search (q1):', aho_corasick_search(query_1, contents))  # Output: True\n",
    "print('aho_corasick_search (q2):', aho_corasick_search(query_2, contents))  # Output: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm            Time (seconds) \n",
      "-----------------------------------\n",
      "Regex Search         0.018028       \n",
      "Native Search        0.187474       \n",
      "Rabin-Karp Search    0.282420       \n",
      "Aho-Corasick Search  0.328304       \n",
      "KMP Search           0.403537       \n",
      "----------------------------------- \n",
      "\n",
      "\n",
      "Benchmark report saved to reports/benchmark.pdf\n"
     ]
    }
   ],
   "source": [
    "from fsearch.utils import benchmark_algorithms\n",
    "\n",
    "file_path = \"samples/200k.txt\"\n",
    "report_path = 'reports/benchmark.pdf'\n",
    "\n",
    "benchmark_algorithms(file_path, report_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import timeit\n",
    "import weasyprint\n",
    "import base64\n",
    "import pandas as pd\n",
    "from fsearch.algorithms import regex_search, rabin_karp_search, kmp_search, aho_corasick_search, native_search\n",
    "\n",
    "def read_file(file_path: str) -> str:\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import timeit\n",
    "from typing import List, Dict\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import weasyprint\n",
    "import base64\n",
    "\n",
    "# Create a pdf report of the results\n",
    "report_template : str = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Benchmark Results</title>\n",
    "        <style>\n",
    "            body {{\n",
    "                font-family: Arial, sans-serif;\n",
    "                margin: 5px;\n",
    "            }}\n",
    "            .header {{\n",
    "                text-align: center;\n",
    "                margin-bottom: 50px;\n",
    "            }}\n",
    "            .plot {{\n",
    "                text-align: center;\n",
    "                margin: 20px 5px;\n",
    "            }}\n",
    "            .table {{\n",
    "                margin: 10px;\n",
    "            }}\n",
    "            \n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"header\">\n",
    "            <h1>Benchmarking Search Algorithms</h1>\n",
    "        </div>\n",
    "        <div class=\"table\">\n",
    "            <pre>{table_str}</pre>\n",
    "        </div>\n",
    "        <div class=\"plot\">\n",
    "            <img src=\"data:image/png;base64,{img_str}\" alt=\"Benchmark Plot\">\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_samples(file_path: str, size: int = 10) -> List[str]:\n",
    "    \"\"\"\n",
    "    Sample random lines from a file.\n",
    "\n",
    "    Args:\n",
    "        - file_path (str): Path to the file.\n",
    "        - size (int): Number of lines to sample. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of sampled lines.\n",
    "    \"\"\"\n",
    "    lines = read_file(file_path).split(\"\\n\")\n",
    "    total = len(lines)\n",
    "\n",
    "    if size > total:\n",
    "        size = total\n",
    "    \n",
    "    sampled_lines = random.sample(lines, size)\n",
    "    return sampled_lines\n",
    "\n",
    "def plot_benchmarks(results: Dict[str, Dict[str, float]]) -> BytesIO:\n",
    "    \"\"\"\n",
    "    Plots a grouped bar chart for the benchmark results and returns the BytesIO object.\n",
    "\n",
    "    Args:\n",
    "        results (dict): A dictionary containing the algorithm names as keys and another dictionary as values,\n",
    "                        where the keys are file sizes and the values are execution times.\n",
    "\n",
    "    Returns:\n",
    "        BytesIO: The BytesIO object containing the plot image.\n",
    "    \"\"\"\n",
    "    algorithms = list(results.keys())\n",
    "    file_sizes = list(results[algorithms[0]].keys())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    width = 0.15\n",
    "    x = range(len(file_sizes))\n",
    "\n",
    "    for i, algorithm in enumerate(algorithms):\n",
    "        times = [results[algorithm][file_size] for file_size in file_sizes]\n",
    "        ax.bar([pos + i * width for pos in x], times, width, label=algorithm)\n",
    "\n",
    "    ax.set_xlabel('File Size')\n",
    "    ax.set_ylabel('Time (seconds)')\n",
    "    ax.set_title('Benchmark of Search Algorithms')\n",
    "    ax.set_xticks([pos + width * (len(algorithms) / 2) for pos in x])\n",
    "    ax.set_xticklabels(file_sizes)\n",
    "    ax.legend()\n",
    "\n",
    "    buffer = BytesIO()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(buffer, format='png')\n",
    "    buffer.seek(0)\n",
    "    plt.close()\n",
    "\n",
    "    return buffer\n",
    "\n",
    "def print_benchmarks(results: Dict[str, Dict[str, float]]) -> str:\n",
    "    \"\"\"\n",
    "    Pretty prints the benchmark results as a table.\n",
    "\n",
    "    Args:\n",
    "        results (dict[str, dict[str, float]]): A dictionary with algorithm names as keys and dictionaries of file sizes and times as values.\n",
    "\n",
    "    Returns:\n",
    "    str: The table string representation of the results.\n",
    "    \"\"\"\n",
    "    file_sizes = list(next(iter(results.values())).keys())\n",
    "    headers = [\"Algorithm\"] + file_sizes + [\"Average\"]\n",
    "    row_format = \"{:<20}\" + \"{:<15}\" * (len(headers) - 1)\n",
    "    \n",
    "    table_str = row_format.format(*headers) + \"\\n\"\n",
    "    table_str += \"-\" * 20 + \"-\" * 15 * (len(headers) - 1) + \"\\n\"\n",
    "\n",
    "    for algorithm, times in results.items():\n",
    "        avg_time = sum(times.values()) / len(times)\n",
    "        row = [algorithm] + [f\"{times[file_size]:.6f}\" for file_size in file_sizes] + [f\"{avg_time:.6f}\"]\n",
    "        table_str += row_format.format(*row) + \"\\n\"\n",
    "\n",
    "    table_str += \"-\" * 20 + \"-\" * 15 * (len(headers) - 1) + \"\\n\"\n",
    "    print(table_str)\n",
    "    return table_str\n",
    "\n",
    "def benchmark_algorithms(file_paths: List[str], report_path: str, sample_size: int = 11):\n",
    "    \"\"\"\n",
    "    Benchmarks the different search algorithms using the content of the specified files and patterns\n",
    "    sampled from the files, then creates a PDF report with the plotted benchmark results using WeasyPrint.\n",
    "\n",
    "    Args:\n",
    "        file_paths (list): A list of paths to the search files.\n",
    "        pattern (str): The pattern to search for in the files.\n",
    "        report_path (str): The path the benchmark PDF report will be saved to.\n",
    "        sample_size (int): Number of lines to sample for generating patterns.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    algorithms = {\n",
    "        'Native Search': native_search,\n",
    "        'Rabin-Karp Search': rabin_karp_search,\n",
    "        'KMP Search': kmp_search,\n",
    "        'Aho-Corasick Search': aho_corasick_search,\n",
    "        'Regex Search': regex_search\n",
    "    }\n",
    "    \n",
    "    results = {algorithm: {} for algorithm in algorithms.keys()}\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            text = read_file(file_path)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            #file_size_label = f\"{file_size / 1024:.2f} KB\" if file_size < 1024 ** 2 else f\"{file_size / 1024 ** 2:.2f} MB\"\n",
    "            file_size_label = sum(1 for i in open(file_path, 'rb'))\n",
    "            pattern = generate_samples(file_path, 1)[0]\n",
    "            for name, algorithm in algorithms.items():\n",
    "                timer = timeit.Timer(lambda: algorithm(text, pattern))\n",
    "                time_taken = timer.timeit(number=1)  # Run the algorithm 10 times and get the average time\n",
    "                if file_size_label not in results[name]:\n",
    "                    results[name][file_size_label] = []\n",
    "                results[name][file_size_label].append(time_taken)\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File at path {file_path} not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred with file {file_path}: {e}\")\n",
    "\n",
    "    avg_results = {algorithm: {file_size: sum(times) / len(times) for file_size, times in result.items()} for algorithm, result in results.items()}\n",
    "    sorted_results = dict(sorted(avg_results.items(), key=lambda item: sum(item[1].values()) / len(item[1].values())))\n",
    "\n",
    "    # Pretty print the results\n",
    "    table_str = print_benchmarks(sorted_results)\n",
    "\n",
    "    # Plot the results\n",
    "    plot_img = plot_benchmarks(sorted_results)\n",
    "    img_str = base64.b64encode(plot_img.read()).decode('utf-8')\n",
    "    \n",
    "    report_template = report_template.format(table_str=table_str, img_str=img_str)\n",
    "    weasyprint.HTML(string=report_template).write_pdf(report_path)\n",
    "    print(f\"Benchmark report saved to {report_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples/200k.txt\n",
      "samples/400k.txt\n",
      "Algorithm           271100         813300         Average        \n",
      "-----------------------------------------------------------------\n",
      "Regex Search        0.003694       0.001705       0.002699       \n",
      "Native Search       0.019504       0.065433       0.042469       \n",
      "Rabin-Karp Search   0.038471       0.062112       0.050291       \n",
      "KMP Search          0.064064       0.068926       0.066495       \n",
      "Aho-Corasick Search 0.057100       0.076279       0.066689       \n",
      "-----------------------------------------------------------------\n",
      "\n",
      "Benchmark report saved to benchmark_results.pdf\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_paths = [\n",
    "    \"samples/200k.txt\",\n",
    "    \"samples/400k.txt\"\n",
    "]\n",
    "#from fsearch.utils import benchmark_algorithms\n",
    "\n",
    "report_path = 'benchmark_results.pdf'\n",
    "\n",
    "benchmark_algorithms(file_paths, report_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./setup.py\n",
      "./LICENSE\n",
      "./README.md\n",
      "./Makefile\n",
      "./notebook.ipynb\n",
      "./Archive.zip\n",
      "./.git\n",
      "./samples\n",
      "./fsearch.egg-info\n",
      "./.certs\n",
      "./__pycache__\n",
      "./fsearch\n",
      "./.gitignore\n",
      "./reports\n",
      "./config.ini\n",
      "./tests\n",
      "./pytest.ini\n",
      "./conftest.py\n",
      "./requirements.txt\n",
      "./.vscode\n",
      "./.pytest_cache\n",
      "./.coverage\n",
      "./client.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for file in os.scandir():\n",
    "    print(file.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "list(itertools.accumulate(range(10), pow))\n",
    "list(map(pow, range(10), itertools.repeat(2)))\n",
    "len(list(range(10000, 1000000, 100000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000, 120000, 230000, 340000, 450000, 560000, 670000, 780000, 890000, 1000000, 10000, 120000, 230000, 340000, 450000, 560000, 670000, 780000, 890000, 1000000, 10000, 120000, 230000, 340000, 450000, 560000, 670000, 780000, 890000, 1000000, 10000, 120000, 230000, 340000, 450000, 560000, 670000, 780000, 890000, 1000000, 10000, 120000, 230000, 340000, 450000, 560000, 670000, 780000, 890000, 1000000, 10000, 120000, 230000, 340000, 450000, 560000, 670000, 780000, 890000, 1000000, 10000, 120000, 230000, 340000, 450000, 560000, 670000, 780000, 890000, 1000000, 10000, 120000, 230000, 340000, 450000, 560000, 670000, 780000, 890000, 1000000, 10000, 120000, 230000, 340000, 450000, 560000, 670000, 780000, 890000, 1000000, 10000, 120000, 230000, 340000, 450000, 560000, 670000, 780000, 890000, 1000000]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "def loop_with_accumulate(start: int = 10000, end: int = 1000000, steps: int = 10):\n",
    "    \"\"\"\n",
    "    Loops from start to end, stepping a specified number of times using itertools.accumulate,\n",
    "    and repeats the loop 10 times.\n",
    "\n",
    "    Args:\n",
    "        start (int): The starting number. Defaults to 10,000.\n",
    "        end (int): The ending number. Defaults to 1,000,000.\n",
    "        steps (int): The number of steps to take between start and end. Defaults to 10.\n",
    "    \"\"\"\n",
    "    step_size = (end - start) // (steps - 1)\n",
    "    increments = [step_size] * (steps - 1)\n",
    "    out = []\n",
    "    for i in range(10):\n",
    "        sequence = itertools.accumulate([start] + increments)\n",
    "        for num in sequence:\n",
    "            # Perform any operation here\n",
    "            out.append(num)\n",
    "    print(out)\n",
    "    return out\n",
    "# Example usage\n",
    "x = loop_with_accumulate()\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a function that print this python value \n",
    "```\n",
    "{\n",
    "    '10000-kb': {\n",
    "        10: {38.31242800151813, 63.6}\n",
    "    },\n",
    "    '20000-kb': {10: {33.3, 60.6}},\n",
    "}\n",
    "```\n",
    "to a table string of like below format\n",
    "\n",
    "Queries| 10000-kb  | 20000-kb   |\n",
    "------- ----------- ------------\n",
    "10     | 38.3, 63.6| 33.3, 60.6 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries | 10000-kb   | 20000-kb  \n",
      "10      | 38.3, 63.6 | 33.3, 60.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def format_dict_to_table(data: dict) -> str:\n",
    "    \"\"\"\n",
    "    Formats the nested dictionary into a table string.\n",
    "    \n",
    "    Args:\n",
    "        data (dict): The dictionary to format.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted table string.\n",
    "    \"\"\"\n",
    "    # Extract headers from the dictionary keys\n",
    "    headers = ['Queries'] + list(data.keys())\n",
    "    \n",
    "    # Initialize the rows list with the header\n",
    "    rows = [headers]\n",
    "    \n",
    "    # Get the unique query numbers (like 10) from the nested dictionaries\n",
    "    queries = sorted({query for subdict in data.values() for query in subdict.keys()})\n",
    "    \n",
    "    for query in queries:\n",
    "        # Initialize a row with the current query number\n",
    "        row = [str(query)]\n",
    "        for key in data.keys():\n",
    "            # Get the set of values for the current query number\n",
    "            values_set = data[key].get(query)\n",
    "            if values_set:\n",
    "                # Format the values as comma-separated strings\n",
    "                formatted_values = ', '.join(f\"{value:.1f}\" for value in sorted(values_set))\n",
    "            else:\n",
    "                formatted_values = ''\n",
    "            row.append(formatted_values)\n",
    "        # Add the formatted row to the rows list\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Calculate the maximum width of each column\n",
    "    col_widths = [max(len(str(item)) for item in col) for col in zip(*rows)]\n",
    "    \n",
    "    # Build the formatted table string\n",
    "    table = \"\"\n",
    "    for row in rows:\n",
    "        formatted_row = \" | \".join(str(item).ljust(width) for item, width in zip(row, col_widths))\n",
    "        table += f\"{formatted_row}\\n\"\n",
    "    \n",
    "    return table\n",
    "\n",
    "# Example usage\n",
    "data = {\n",
    "    '10000-kb': {10: {38.31242800151813, 63.6}},\n",
    "    '20000-kb': {10: {33.3, 60.6}},\n",
    "}\n",
    "\n",
    "table_str = format_dict_to_table(data)\n",
    "print(table_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries | 10000-kb    | 20000-kb   \n",
      "------- | ----------- | -----------\n",
      "10      | 38.3 | 63.6 | 33.3 | 60.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def format_dict_to_table(data: dict) -> str:\n",
    "    \"\"\"\n",
    "    Formats the nested dictionary into a table string with underscores under headers.\n",
    "    \n",
    "    Args:\n",
    "        data (dict): The dictionary to format.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted table string.\n",
    "    \"\"\"\n",
    "    # Extract headers from the dictionary keys\n",
    "    headers = ['Queries'] + list(data.keys())\n",
    "    \n",
    "    # Initialize the rows list with the header\n",
    "    rows = [headers]\n",
    "    \n",
    "    # Get the unique query numbers (like 10) from the nested dictionaries\n",
    "    queries = sorted({query for subdict in data.values() for query in subdict.keys()})\n",
    "    \n",
    "    for query in queries:\n",
    "        # Initialize a row with the current query number\n",
    "        row = [str(query)]\n",
    "        for key in data.keys():\n",
    "            # Get the set of values for the current query number\n",
    "            values_set = data[key].get(query)\n",
    "            if values_set:\n",
    "                # Format the values as comma-separated strings\n",
    "                formatted_values = ' | '.join(f\"{value:.1f}\" for value in sorted(values_set))\n",
    "            else:\n",
    "                formatted_values = ''\n",
    "            row.append(formatted_values)\n",
    "        # Add the formatted row to the rows list\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Calculate the maximum width of each column\n",
    "    col_widths = [max(len(str(item)) for item in col) for col in zip(*rows)]\n",
    "    \n",
    "    # Build the formatted table string\n",
    "    table = \"\"\n",
    "    \n",
    "    # Format the header row\n",
    "    header_row = \" | \".join(str(item).ljust(width) for item, width in zip(rows[0], col_widths))\n",
    "    table += f\"{header_row}\\n\"\n",
    "    \n",
    "    # Add the underline row\n",
    "    underline_row = \" | \".join('-' * width for width in col_widths)\n",
    "    table += f\"{underline_row}\\n\"\n",
    "    \n",
    "    # Add the data rows\n",
    "    for row in rows[1:]:\n",
    "        formatted_row = \" | \".join(str(item).ljust(width) for item, width in zip(row, col_widths))\n",
    "        table += f\"{formatted_row}\\n\"\n",
    "    \n",
    "    return table\n",
    "\n",
    "# Example usage\n",
    "data = {\n",
    "    '10000-kb': {10: {38.31242800151813, 63.6}},\n",
    "    '20000-kb': {10: {33.3, 60.6}},\n",
    "}\n",
    "\n",
    "table_str = format_dict_to_table(data)\n",
    "print(table_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'fsearch-3.9 (Python 3.9.19)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n fsearch-3.9 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "def write_config(config_path: str, configs):\n",
    "    \"\"\"\n",
    "    Writes the provided configuration dictionary to a file.\n",
    "\n",
    "    Parameters:\n",
    "        config_path : str\n",
    "            The file path where the configuration should be written.\n",
    "\n",
    "        configs : Dict[str, str]\n",
    "            A dictionary containing configuration key-value pairs to be written\n",
    "            under the 'DEFAULT' section of the configuration file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config[\"DEFAULT\"] = configs\n",
    "    with open(config_path, \"w\") as configfile:\n",
    "        config.write(configfile)\n",
    "\n",
    "c = {\"host\": 1234,\"port\": 8080, \"linux_path\":'jimmy', \"REREAD_ON_QUERY\": False}\n",
    "#write_config('.test-conf', c)\n",
    "from fsearch.utils import read_config\n",
    "read_config('.test-conf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
